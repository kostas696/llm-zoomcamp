{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41d27bc",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "from fastembed.embedding import TextEmbedding\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d7f1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\User\\Miniconda3\\envs\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\AppData\\Local\\Temp\\fastembed_cache\\models--xenova--jina-embeddings-v2-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:33<00:00,  6.75s/it]\n"
     ]
    }
   ],
   "source": [
    "embedder = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "298eb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"I just discovered the course. Can I join now?\"]\n",
    "embedding = list(embedder.embed(query))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adef1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (512,)\n",
      "Min value: -0.11726374368207196\n",
      "Norm: 1.0\n",
      "Cosine similarity with self: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {embedding.shape}\")       \n",
    "print(f\"Min value: {np.min(embedding)}\") \n",
    "print(f\"Norm: {np.linalg.norm(embedding)}\")  \n",
    "print(f\"Cosine similarity with self: {np.dot(embedding, embedding)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e0a9f",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01073b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.45304216e-02, -7.83451890e-02,  3.13610220e-02,  2.34234659e-02,\n",
       "       -3.06321531e-02, -5.51041666e-02,  2.24726443e-02,  1.50385846e-02,\n",
       "       -1.81159603e-02,  1.80595452e-02, -4.80892935e-03, -7.57395912e-02,\n",
       "       -4.87269909e-03, -9.07717914e-02,  4.83940834e-02, -4.26317335e-02,\n",
       "       -2.61462336e-02, -4.48128965e-02, -2.06925942e-02, -3.79054456e-02,\n",
       "       -3.30329167e-02, -8.02849907e-03,  1.18560345e-02, -3.83721145e-02,\n",
       "        7.26378193e-02, -5.82811814e-02, -7.30890323e-02,  3.40911395e-02,\n",
       "        5.60705315e-02,  5.02685143e-02, -5.99293168e-02,  5.33016965e-02,\n",
       "       -1.79524626e-02,  4.17743639e-03, -2.45427843e-02,  1.32287952e-02,\n",
       "        4.64178283e-02,  1.09963757e-02, -1.01500014e-02, -5.77526538e-03,\n",
       "       -2.83983710e-04,  4.91496421e-02,  1.11214846e-01, -2.76306435e-02,\n",
       "       -6.78923782e-02, -1.85928277e-02, -1.23963215e-01,  1.25745908e-02,\n",
       "        1.65298563e-02,  7.22242041e-03, -2.77237445e-02,  5.18073796e-02,\n",
       "       -5.98604691e-02,  5.27339295e-02,  1.03843986e-02,  4.82091179e-02,\n",
       "       -2.29023177e-02,  1.58799907e-02, -4.80511644e-02,  1.02489305e-02,\n",
       "        1.37884429e-02,  3.87444956e-02, -5.79894319e-02,  5.69139315e-02,\n",
       "       -3.15205301e-02, -2.67498609e-02, -4.48054497e-02, -4.09707665e-02,\n",
       "       -9.20447588e-02, -5.96115320e-03, -5.49335653e-02, -5.34223063e-03,\n",
       "        6.68054848e-02, -5.45217541e-02, -8.69841281e-03,  1.40446548e-02,\n",
       "       -3.96009012e-02,  3.93236723e-02, -1.96751673e-02, -1.63111148e-03,\n",
       "       -6.80347918e-03, -3.31599599e-02,  4.85879696e-03, -3.88989149e-02,\n",
       "       -3.40546225e-03, -5.19890664e-02,  3.08150602e-02, -2.70411315e-02,\n",
       "        6.88027294e-02, -8.59181537e-04, -3.05577823e-02,  8.06859727e-02,\n",
       "       -1.86169560e-02, -6.45329006e-02, -5.04276403e-02, -3.78118046e-02,\n",
       "        5.99760148e-02,  6.87334169e-02,  1.12125033e-02,  1.64547844e-02,\n",
       "        1.13036676e-01, -1.46292393e-02,  1.01782254e-01, -3.40158955e-02,\n",
       "        3.43852485e-02,  3.75869117e-02, -5.58573136e-02,  3.10790905e-03,\n",
       "       -1.16664057e-01, -9.97799397e-03,  1.49959894e-02, -6.87050484e-02,\n",
       "       -3.29115369e-02, -5.93686964e-03, -6.92624552e-02,  1.50800696e-02,\n",
       "        5.85119092e-02, -5.48487749e-02, -2.57178927e-02, -3.56007242e-02,\n",
       "        7.27634408e-05,  5.30020580e-04, -3.35285446e-02,  2.12704996e-02,\n",
       "        4.95065408e-02,  3.66363014e-02, -2.25050799e-03,  2.65128745e-02,\n",
       "       -3.22989896e-02, -6.86249910e-03, -1.34442293e-02, -8.08964061e-03,\n",
       "       -1.29107330e-02,  2.48041390e-02,  1.40144090e-01, -3.86588512e-02,\n",
       "        2.50564771e-02,  3.87349554e-02, -6.14516954e-02,  3.54396397e-02,\n",
       "       -4.25164358e-02, -6.41691295e-02,  4.63288999e-02, -3.24397493e-02,\n",
       "       -2.88255856e-02,  1.30963968e-02,  4.53634894e-02, -2.12361004e-02,\n",
       "       -5.38994185e-02, -1.28039333e-03, -2.08222558e-02,  3.93942256e-02,\n",
       "       -8.17919906e-02,  2.61447131e-02,  4.93715618e-03,  8.39671454e-02,\n",
       "       -2.85633157e-02,  4.62934306e-02,  1.30851343e-02,  4.34114077e-03,\n",
       "       -1.46118649e-02,  5.56021056e-02,  3.25520142e-03, -6.56958766e-02,\n",
       "       -1.24809933e-02, -9.01518384e-03,  4.67927784e-02,  7.14784970e-02,\n",
       "       -3.47358204e-02,  6.19006542e-03,  5.82341908e-02,  3.13632593e-02,\n",
       "       -8.91560611e-02,  2.30164960e-02, -7.31166087e-02, -2.48622002e-02,\n",
       "       -1.95075777e-02,  1.90116327e-02, -3.80645966e-02, -3.41198662e-02,\n",
       "        5.10554042e-02, -3.43794755e-02, -2.66989176e-02,  9.70198212e-03,\n",
       "        1.08240365e-02, -7.85933702e-02, -3.84566947e-02,  1.56839207e-02,\n",
       "        3.80449142e-02, -2.26454217e-02, -4.78608831e-03,  1.15100589e-02,\n",
       "        3.60982291e-03, -1.89996749e-02, -1.79271900e-02,  3.68780675e-02,\n",
       "       -2.10015231e-02,  2.36492865e-02,  1.40564047e-02,  3.52253033e-03,\n",
       "        2.71353991e-02,  7.65226606e-02, -6.01290706e-02,  3.05162455e-02,\n",
       "       -4.58806828e-02,  2.24898402e-02, -2.50920266e-02, -5.63759400e-02,\n",
       "       -2.29451723e-02, -4.27856883e-03,  3.57165247e-02, -3.55258332e-03,\n",
       "        8.91507661e-02,  2.12670568e-02, -3.74739535e-04, -2.24271478e-02,\n",
       "       -2.19664301e-02, -4.18970854e-02,  2.65568239e-02, -3.93783666e-02,\n",
       "       -1.68303318e-03,  1.26468124e-02,  4.43983500e-03,  5.05578821e-02,\n",
       "       -2.44747125e-02, -3.94392464e-02,  1.52638210e-02,  1.28973286e-02,\n",
       "       -3.15466906e-03, -4.72592990e-02,  1.17825048e-01, -5.25536691e-02,\n",
       "       -5.32448419e-02,  1.05159507e-02,  4.58077245e-02, -2.47739657e-02,\n",
       "       -2.57602260e-03, -2.19756086e-02, -3.87667442e-02, -1.36106484e-02,\n",
       "       -4.98464148e-02,  6.12117259e-03,  5.66379871e-02, -3.23384664e-02,\n",
       "        1.20039332e-03,  3.52746010e-02,  5.16079192e-02, -3.62631444e-02,\n",
       "        5.62710699e-02,  5.33073513e-02, -3.63443013e-02, -4.03703333e-02,\n",
       "       -3.61991046e-02, -6.26061191e-02, -8.31570326e-03,  4.13882108e-02,\n",
       "       -2.88730240e-02,  5.22493907e-02, -7.34401949e-02, -3.53566503e-02,\n",
       "        2.09848689e-02,  6.31085491e-02,  4.60985920e-03,  9.63700572e-02,\n",
       "       -9.67374144e-03, -8.95209012e-03, -7.69227037e-02, -9.60891677e-03,\n",
       "        2.14770283e-02,  2.30009061e-02,  3.10542081e-03,  5.05152356e-03,\n",
       "        1.63936602e-02, -2.06680943e-02, -6.06017693e-02, -3.03882950e-02,\n",
       "        4.96442029e-02,  2.03350312e-02,  3.66350182e-02, -3.95295668e-02,\n",
       "       -5.11060311e-02,  3.16693161e-02,  4.38041992e-03,  2.21187562e-02,\n",
       "        5.62608999e-02, -1.41864971e-02,  3.59695854e-02,  7.59520869e-02,\n",
       "        1.06047227e-01,  1.45019405e-03,  6.03234977e-03, -9.00573683e-02,\n",
       "       -5.01267089e-03, -3.23071388e-02, -2.46832217e-03,  8.69799606e-02,\n",
       "        5.06123668e-02,  2.36965572e-02,  8.11533597e-03,  5.54493872e-02,\n",
       "        1.77999434e-02,  3.11199896e-02, -3.55622519e-02, -2.52925100e-02,\n",
       "        2.31455231e-02,  1.59941068e-02,  3.10115297e-02, -1.54522132e-02,\n",
       "       -1.63243394e-02, -6.25963401e-02,  5.73597219e-03, -4.68481070e-02,\n",
       "       -2.48465897e-02,  4.29610440e-02,  5.32249062e-02,  1.77272696e-03,\n",
       "        3.37805635e-02, -8.39864603e-02, -5.38050364e-02,  1.18949223e-02,\n",
       "       -6.61884172e-03, -3.89601862e-02,  5.77476215e-02,  2.07156306e-02,\n",
       "        3.59911673e-02,  5.05872120e-02, -6.44578575e-02,  3.32006131e-03,\n",
       "        1.10723310e-02, -1.86581649e-02, -1.85738158e-02,  1.27308839e-03,\n",
       "       -4.62866670e-02, -7.17191851e-02, -4.19461413e-02, -1.31517460e-03,\n",
       "       -2.92806199e-02, -8.03236406e-02,  1.29327211e-02, -3.37090877e-02,\n",
       "        2.93104203e-02, -3.75803517e-03, -1.44845994e-03,  1.00548282e-01,\n",
       "       -1.00564837e-02, -2.46266165e-02,  4.05392073e-02,  3.35890540e-03,\n",
       "       -5.34469609e-02, -2.54327991e-02, -1.52543803e-02, -1.43709349e-02,\n",
       "       -1.85677428e-02, -2.13969974e-03, -8.73001862e-02, -1.60633701e-02,\n",
       "        3.02461531e-02, -3.49063000e-02, -2.25649433e-02,  1.00616130e-01,\n",
       "        3.00223473e-03, -5.50977902e-02, -2.35539193e-02,  9.52522525e-02,\n",
       "        6.92015790e-02, -2.18485321e-02,  2.49092154e-04, -3.49070656e-02,\n",
       "        4.73735761e-02,  3.60143410e-02,  8.32714695e-02,  4.12549525e-02,\n",
       "        2.54143606e-02, -4.85554913e-02,  2.74004159e-02, -3.80426653e-02,\n",
       "        5.91278013e-02,  2.53244783e-02, -3.36910575e-02, -1.90901566e-02,\n",
       "        2.96261799e-02,  2.43380914e-02, -2.39162695e-02, -4.51288532e-02,\n",
       "       -2.72568370e-02,  1.09330517e-02,  1.86310554e-02, -1.84974203e-03,\n",
       "        9.46878307e-03, -1.15559411e-02, -2.49243816e-02, -3.50724680e-02,\n",
       "       -4.03738801e-02,  4.19630679e-02,  6.67691088e-02, -7.30262298e-02,\n",
       "        7.56360325e-02,  6.06346272e-02, -1.56064506e-03,  2.90626635e-02,\n",
       "       -1.98712837e-02,  2.15630919e-02, -3.38016074e-02, -7.29602935e-03,\n",
       "       -2.44389218e-02, -1.63480500e-02, -7.87498696e-02, -2.56954734e-02,\n",
       "        1.40306742e-02,  3.25408063e-03,  5.29974506e-02,  1.83844454e-02,\n",
       "        3.41865804e-02,  3.95536667e-02, -3.88302965e-02, -7.36927455e-02,\n",
       "       -9.04139956e-02, -4.75587521e-02, -2.62919167e-02,  8.76068777e-03,\n",
       "        1.85204623e-02,  5.71211183e-03, -2.31337457e-02,  3.00751692e-02,\n",
       "        5.58853079e-02,  6.04652236e-03,  4.20380170e-02, -4.43148375e-02,\n",
       "        6.09016247e-02,  2.15545726e-02, -1.55159075e-02, -5.18127285e-02,\n",
       "       -2.88611787e-02,  4.96420552e-02, -1.73781857e-02,  2.22649703e-02,\n",
       "        1.84093435e-02, -5.65759579e-02,  5.26079970e-02, -4.37273385e-03,\n",
       "        9.75568557e-02, -8.76182227e-02,  3.84923422e-02,  3.43069149e-02,\n",
       "        1.00228260e-01,  8.32310554e-02,  1.39729759e-02, -2.92088436e-02,\n",
       "       -2.64612614e-02,  4.50595800e-02,  4.50768174e-02,  6.56265451e-02,\n",
       "       -2.57148549e-02,  4.38141350e-02, -9.09203397e-03,  3.24566834e-02,\n",
       "       -1.00524233e-02, -1.22899828e-01,  2.63783388e-02,  4.24369481e-02,\n",
       "        4.16517015e-02, -5.68288691e-02, -9.15504761e-02,  1.93085662e-02,\n",
       "       -1.13468163e-02, -1.24219554e-02,  2.57254890e-02,  3.38115672e-02,\n",
       "        1.95534978e-02, -9.04631285e-03,  4.81675875e-03, -6.69664763e-02,\n",
       "        1.04124747e-03,  2.12351905e-02,  9.02697179e-02,  3.46080759e-02,\n",
       "        5.17977427e-02,  4.47683065e-02, -6.94026550e-02,  9.75395322e-02,\n",
       "       -4.64396121e-02, -6.05067688e-02, -7.17751462e-02, -6.16598849e-02,\n",
       "       -4.22837097e-02,  6.49295787e-04,  1.48002740e-02, -4.33542958e-03,\n",
       "        9.91974214e-02,  2.36802438e-02, -5.63740147e-02, -6.30382800e-02,\n",
       "        6.47441090e-03, -2.77447442e-02, -4.93521109e-02,  8.95177342e-03,\n",
       "        6.34117737e-03, -3.77701293e-02,  8.46668669e-02,  3.98892480e-02,\n",
       "        4.74573178e-02, -7.41830435e-02,  4.04689464e-02,  6.57271380e-02,\n",
       "       -1.06213702e-02,  2.96078129e-02, -6.05322399e-03, -3.26904300e-02,\n",
       "       -7.25063705e-02,  7.73107326e-02,  5.61754052e-02,  6.20516138e-03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embed a new document and calculate the cosine similarity with the query embedding\n",
    "doc = [\"Can I still join the course after the start date?\"]\n",
    "doc_vec = list(embedder.embed(doc))[0]\n",
    "doc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad85e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity\n",
    "similarity = np.dot(embedding, doc_vec)\n",
    "print(f\"Cosine similarity: {similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d381e4",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8727ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the documents for embedding\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "     'question': 'Course - Can I still join the course after the start date?'},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "     'question': 'Course - Can I follow the course after it finishes?'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "     'question': 'Course - When will the course start?'},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "     'question': 'Course - What can I do before the course starts?'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "     'question': 'How can we contribute to the course?'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fec54c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: Highest similarity index: 1\n"
     ]
    }
   ],
   "source": [
    "# Embed documents' text fields\n",
    "doc_texts = [doc[\"text\"] for doc in documents]\n",
    "doc_embeddings = list(embedder.embed(doc_texts))\n",
    "\n",
    "# Convert to matrix for dot product\n",
    "doc_matrix = np.vstack(doc_embeddings)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarities = doc_matrix @ embedding   # Dot product with the query embedding\n",
    "\n",
    "# Get highest similarity index\n",
    "best_index_q3 = np.argmax(similarities)\n",
    "print(f\"Q3: Highest similarity index: {best_index_q3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ed9ec",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82884ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4: Highest similarity index: 0\n"
     ]
    }
   ],
   "source": [
    "# Create new combined field\n",
    "full_texts = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "full_embeddings = list(embedder.embed(full_texts))\n",
    "full_matrix = np.vstack(full_embeddings)\n",
    "\n",
    "# Compute similarity again\n",
    "similarities_full = full_matrix @ embedding  # Dot product with the query embedding\n",
    "best_index_q4 = np.argmax(similarities_full)\n",
    "print(f\"Q4: Highest similarity index: {best_index_q4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109080b",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a4a42d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>description</th>\n",
       "      <th>license</th>\n",
       "      <th>size_in_GB</th>\n",
       "      <th>dim</th>\n",
       "      <th>tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 256...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-xs</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.067</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.220</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAAI/bge-small-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAAI/bge-small-zh-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), Chinese, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.090</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qdrant/clip-ViT-B-32-text</td>\n",
       "      <td>Text embeddings, Multimodal (text&amp;image), Engl...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.250</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jinaai/jina-embeddings-v2-small-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 819...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-code</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5-Q</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thenlper/gte-base</td>\n",
       "      <td>General text embeddings, Unimodal (text), supp...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.440</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-es</td>\n",
       "      <td>Text embeddings, Unimodal (text), supports mix...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-zh</td>\n",
       "      <td>Text embeddings, Unimodal (text), supports mix...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BAAI/bge-base-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.420</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 819...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jinaai/jina-clip-v1</td>\n",
       "      <td>Text embeddings, Multimodal (text&amp;image), Engl...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m-long</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 204...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.540</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.210</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-de</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.320</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>mit</td>\n",
       "      <td>2.240</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-l</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BAAI/bge-large-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jinaai/jina-embeddings-v3</td>\n",
       "      <td>Multi-task unimodal (text) embedding model, mu...</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>2.290</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'retrieval.query': 0, 'retrieval.passage': 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "0              sentence-transformers/all-MiniLM-L6-v2   \n",
       "1                 snowflake/snowflake-arctic-embed-xs   \n",
       "2                              BAAI/bge-small-en-v1.5   \n",
       "3                  snowflake/snowflake-arctic-embed-s   \n",
       "4   sentence-transformers/paraphrase-multilingual-...   \n",
       "5                                   BAAI/bge-small-en   \n",
       "6                              BAAI/bge-small-zh-v1.5   \n",
       "7                           Qdrant/clip-ViT-B-32-text   \n",
       "8                  jinaai/jina-embeddings-v2-small-en   \n",
       "9                        nomic-ai/nomic-embed-text-v1   \n",
       "10  sentence-transformers/paraphrase-multilingual-...   \n",
       "11                jinaai/jina-embeddings-v2-base-code   \n",
       "12                   nomic-ai/nomic-embed-text-v1.5-Q   \n",
       "13                     nomic-ai/nomic-embed-text-v1.5   \n",
       "14                                  thenlper/gte-base   \n",
       "15                  jinaai/jina-embeddings-v2-base-es   \n",
       "16                  jinaai/jina-embeddings-v2-base-zh   \n",
       "17                                   BAAI/bge-base-en   \n",
       "18                  jinaai/jina-embeddings-v2-base-en   \n",
       "19                                jinaai/jina-clip-v1   \n",
       "20            snowflake/snowflake-arctic-embed-m-long   \n",
       "21                 snowflake/snowflake-arctic-embed-m   \n",
       "22                              BAAI/bge-base-en-v1.5   \n",
       "23                  jinaai/jina-embeddings-v2-base-de   \n",
       "24                     intfloat/multilingual-e5-large   \n",
       "25                 snowflake/snowflake-arctic-embed-l   \n",
       "26                                 thenlper/gte-large   \n",
       "27                 mixedbread-ai/mxbai-embed-large-v1   \n",
       "28                             BAAI/bge-large-en-v1.5   \n",
       "29                          jinaai/jina-embeddings-v3   \n",
       "\n",
       "                                          description       license  \\\n",
       "0   Text embeddings, Unimodal (text), English, 256...    apache-2.0   \n",
       "1   Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "2   Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "3   Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "4   Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "5   Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "6   Text embeddings, Unimodal (text), Chinese, 512...           mit   \n",
       "7   Text embeddings, Multimodal (text&image), Engl...           mit   \n",
       "8   Text embeddings, Unimodal (text), English, 819...    apache-2.0   \n",
       "9   Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "10  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "11  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "12  Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "13  Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "14  General text embeddings, Unimodal (text), supp...           mit   \n",
       "15  Text embeddings, Unimodal (text), supports mix...    apache-2.0   \n",
       "16  Text embeddings, Unimodal (text), supports mix...    apache-2.0   \n",
       "17  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "18  Text embeddings, Unimodal (text), English, 819...    apache-2.0   \n",
       "19  Text embeddings, Multimodal (text&image), Engl...    apache-2.0   \n",
       "20  Text embeddings, Unimodal (text), English, 204...    apache-2.0   \n",
       "21  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "22  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "23  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "24  Text embeddings, Unimodal (text), Multilingual...           mit   \n",
       "25  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "26  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "27  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "28  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "29  Multi-task unimodal (text) embedding model, mu...  cc-by-nc-4.0   \n",
       "\n",
       "    size_in_GB   dim                                              tasks  \n",
       "0        0.090   384                                                 {}  \n",
       "1        0.090   384                                                 {}  \n",
       "2        0.067   384                                                 {}  \n",
       "3        0.130   384                                                 {}  \n",
       "4        0.220   384                                                 {}  \n",
       "5        0.130   384                                                 {}  \n",
       "6        0.090   512                                                 {}  \n",
       "7        0.250   512                                                 {}  \n",
       "8        0.120   512                                                 {}  \n",
       "9        0.520   768                                                 {}  \n",
       "10       1.000   768                                                 {}  \n",
       "11       0.640   768                                                 {}  \n",
       "12       0.130   768                                                 {}  \n",
       "13       0.520   768                                                 {}  \n",
       "14       0.440   768                                                 {}  \n",
       "15       0.640   768                                                 {}  \n",
       "16       0.640   768                                                 {}  \n",
       "17       0.420   768                                                 {}  \n",
       "18       0.520   768                                                 {}  \n",
       "19       0.550   768                                                 {}  \n",
       "20       0.540   768                                                 {}  \n",
       "21       0.430   768                                                 {}  \n",
       "22       0.210   768                                                 {}  \n",
       "23       0.320   768                                                 {}  \n",
       "24       2.240  1024                                                 {}  \n",
       "25       1.020  1024                                                 {}  \n",
       "26       1.200  1024                                                 {}  \n",
       "27       0.640  1024                                                 {}  \n",
       "28       1.200  1024                                                 {}  \n",
       "29       2.290  1024  {'retrieval.query': 0, 'retrieval.passage': 1,...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch supported models and inspect key details\n",
    "supported_models = (\n",
    "    pd.DataFrame(TextEmbedding.list_supported_models())\n",
    "    .sort_values(\"dim\")  \n",
    "    .drop(columns=[\"sources\", \"model_file\", \"additional_files\"])  \n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Display the models\n",
    "supported_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987f24b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\User\\Miniconda3\\envs\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\AppData\\Local\\Temp\\fastembed_cache\\models--Qdrant--bge-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:32<00:00,  6.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality: 384\n"
     ]
    }
   ],
   "source": [
    "embedder = TextEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "query = [\"I just discovered the course. Can I join now?\"]\n",
    "embedding = list(embedder.embed(query))[0]\n",
    "\n",
    "print(f\"Dimensionality: {len(embedding)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96098f85",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch documents from the provided URL\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "documents_raw = requests.get(docs_url).json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    if course['course'] != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10912\\86086124.py:10: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize in-memory Qdrant\n",
    "client = QdrantClient(\":memory:\")\n",
    "model = TextEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "collection_name = \"ml_zoomcamp_faq\"\n",
    "\n",
    "# Create collection\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb8f5083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare text and embeddings\n",
    "payloads = []\n",
    "vectors = []\n",
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "    embedding = list(model.embed([text]))[0]\n",
    "    \n",
    "    vectors.append(embedding)\n",
    "    payloads.append(doc)\n",
    "\n",
    "# Upload in bulk\n",
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        PointStruct(id=i, vector=vectors[i], payload=payloads[i])\n",
    "        for i in range(len(documents))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "618623ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top score: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10912\\3686366748.py:5: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    }
   ],
   "source": [
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_vector = list(model.embed([query]))[0]\n",
    "\n",
    "# Search\n",
    "results = client.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_vector,\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "# Highest score\n",
    "score = results[0].score\n",
    "print(f\"Top score: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
